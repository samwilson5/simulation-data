{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the csv with the plot labels and their coordinates"
      ],
      "metadata": {
        "id": "44_j5bmyxMYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqPDFdncUInH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Thesis/Chapter2_simulations/locations/SWRuns_InputMain_BSE898.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz4QPthcUdHn"
      },
      "outputs": [],
      "source": [
        "site = df['Label']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "need to swith from negative to positive coordinates for Livneh"
      ],
      "metadata": {
        "id": "rBfvwEUP1UIy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU9Dk7Y3UiCc"
      },
      "outputs": [],
      "source": [
        "lon = 360+df['X_WGS84']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRywnoSWUoXG"
      },
      "outputs": [],
      "source": [
        "lat = df['Y_WGS84']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some reason for tmax, 1927 and 1928 are swapped in order hence the switch in the code"
      ],
      "metadata": {
        "id": "9JLP9aui08Yw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYJG42BRVZk0"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "ppt_files = glob.glob('/content/drive/MyDrive/SoilWat/Livneh_data/prec*.nc')\n",
        "ppt_files = ppt_files[:66]\n",
        "\n",
        "tmin_files = glob.glob('/content/drive/MyDrive/SoilWat/Livneh_data/tmin*.nc')\n",
        "tmin_files = tmin_files[:66]\n",
        "\n",
        "tmax_files = glob.glob('/content/drive/MyDrive/SoilWat/Livneh_data/tmax*.nc')\n",
        "tmax_files = tmax_files[:66]\n",
        "tmax_files[12], tmax_files[13] = tmax_files[13],tmax_files[12]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this method is great for pulling site by site but it is extremely slow"
      ],
      "metadata": {
        "id": "HoAcEkBl1LTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTaztd2nVC0B"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "for i in range(len(site)):\n",
        "  id = site[i]\n",
        "  lat_id = lat[i]\n",
        "  lon_id = 360+lon[i]\n",
        "  years = list(range(1915,1981))\n",
        "  for i in range(len(ppt_files)):\n",
        "    ppt=xr.open_dataset(ppt_files[i])\n",
        "    ppt_ts=ppt.sel(lon=lon_id, lat=lat_id, method='nearest')\n",
        "    tmax=xr.open_dataset(tmax_files[i])\n",
        "    tmax_ts=tmax.sel(lon=lon_id,lat=lat_id,method='nearest')\n",
        "    tmin=xr.open_dataset(tmin_files[i])\n",
        "    tmin_ts=tmin.sel(lon=lon_id,lat=lat_id,method='nearest')\n",
        "\n",
        "    ppt_ts=ppt_ts.to_array()\n",
        "    tmax_ts=tmax_ts.to_array()\n",
        "    tmin_ts=tmin_ts.to_array()\n",
        "\n",
        "    ppt_df=pd.DataFrame(ppt_ts)\n",
        "    tmax_df=pd.DataFrame(tmax_ts)\n",
        "    tmin_df=pd.DataFrame(tmin_ts)\n",
        "\n",
        "    year=[years[i]] * len(ppt_df.columns)\n",
        "\n",
        "    new = pd.DataFrame({'ppt':ppt_df.iloc[0],'tmax':tmax_df.iloc[0],'tmin':tmin_df.iloc[0],\n",
        "                      'yday':(ppt_df.columns+1),'year':year})\n",
        "    if i == 0:\n",
        "      final_df = new\n",
        "    else:\n",
        "      final_df = pd.concat([final_df,new])\n",
        "  final_df.to_csv(f\"/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/{id}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Li7Z5z1qcgF"
      },
      "outputs": [],
      "source": [
        "year = range(1915,1981)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fast method! results in yearly csv's with a row for each site"
      ],
      "metadata": {
        "id": "jZq6MTYP1Frb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JVh13GQuq91c"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "\n",
        "for i in range(len(ppt_files)):\n",
        "  ppt=xr.open_dataset(ppt_files[i])\n",
        "  big_ppt = ppt.sel(lon=xr.DataArray(lon), lat=xr.DataArray(lat), method='nearest')\n",
        "  big_ppt=big_ppt.to_array()\n",
        "  big_ppt = big_ppt.reindex(space=['dim_0'])\n",
        "  big_ppt_df = pd.DataFrame(big_ppt[0,:,:])\n",
        "  t_ppt_df = big_ppt_df.transpose()\n",
        "  t_ppt_df['site'] = site\n",
        "  t_ppt_df['year'] = year[i]\n",
        "  t_ppt_df.to_csv(f\"/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/ppt_{year[i]}.csv\")\n",
        "  tmax=xr.open_dataset(tmax_files[i])\n",
        "  big_tmax = tmax.sel(lon=xr.DataArray(lon), lat=xr.DataArray(lat), method='nearest')\n",
        "  big_tmax=big_tmax.to_array()\n",
        "  big_tmax = big_tmax.reindex(space=['dim_0'])\n",
        "  big_tmax_df = pd.DataFrame(big_tmax[0,:,:])\n",
        "  t_tmax_df = big_tmax_df.transpose()\n",
        "  t_tmax_df['site'] = site\n",
        "  t_tmax_df['year'] = year[i]\n",
        "  t_tmax_df.to_csv(f\"/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/tmax_{year[i]}.csv\")\n",
        "  tmin=xr.open_dataset(tmin_files[i])\n",
        "  big_tmin = tmin.sel(lon=xr.DataArray(lon), lat=xr.DataArray(lat), method='nearest')\n",
        "  big_tmin=big_tmin.to_array()\n",
        "  big_tmin = big_tmin.reindex(space=['dim_0'])\n",
        "  big_tmin_df = pd.DataFrame(big_tmin[0,:,:])\n",
        "  t_tmin_df = big_tmin_df.transpose()\n",
        "  t_tmin_df['site'] = site\n",
        "  t_tmin_df['year'] = year[i]\n",
        "  t_tmin_df.to_csv(f\"/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/tmin_{year[i]}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "agVwwF2FDT4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the yearly csv's created above"
      ],
      "metadata": {
        "id": "WLyo1cJlxbfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "tmin_files = glob.glob('/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/tmin_*.csv')\n",
        "tmax_files = glob.glob('/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/tmax_*.csv')\n",
        "ppt_files = glob.glob('/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/ppt_*.csv')"
      ],
      "metadata": {
        "id": "BsZr8zbsDSMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv(tmin_files[1])"
      ],
      "metadata": {
        "id": "Cl8cDEscD6xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(test.iloc[:,1:-2].values.ravel(), columns=['Column'])"
      ],
      "metadata": {
        "id": "HJZZWeKvEN4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['site'] = [ele for ele in test['site'] for i in range(len(test.axes[1])-3)]\n",
        "df['year'] = 1916"
      ],
      "metadata": {
        "id": "eyqhsfTaGCYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop creates a single dataframe, where each day (row) for all years has ppt, tmin, tmax for each site (898)"
      ],
      "metadata": {
        "id": "zGSqkDZLxgoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tmin_files)):\n",
        "  tmin = pd.read_csv(tmin_files[i])\n",
        "  tmin_long = pd.DataFrame(tmin.iloc[:,1:-2].values.ravel(), columns = ['Tmin_C'])\n",
        "  tmin_long['site'] = [ele for ele in tmin['site'] for j in range(len(tmin.axes[1])-3)]\n",
        "  tmin_long['year'] = tmin['year'][1]\n",
        "  tmin_long['doy'] = list((range(1,(len(tmin.axes[1])-2))))*len(tmin.index)\n",
        "  if i == 0:\n",
        "    tmin_big = tmin_long\n",
        "  else:\n",
        "    tmin_big = pd.concat([tmin_big,tmin_long])\n",
        "  ##############################################\n",
        "  tmax = pd.read_csv(tmax_files[i])\n",
        "  tmax_long = pd.DataFrame(tmax.iloc[:,1:-2].values.ravel(), columns = ['Tmax_C'])\n",
        "  tmax_long['site'] = [ele for ele in tmax['site'] for j in range(len(tmax.axes[1])-3)]\n",
        "  tmax_long['year'] = tmax['year'][1]\n",
        "  tmax_long['doy'] = list((range(1,(len(tmax.axes[1])-2))))*len(tmax.index)\n",
        "  if i == 0:\n",
        "    tmax_big = tmax_long\n",
        "  else:\n",
        "    tmax_big = pd.concat([tmax_big,tmax_long])\n",
        "  ##############################################\n",
        "  ppt = pd.read_csv(ppt_files[i])\n",
        "  ppt_long = pd.DataFrame(ppt.iloc[:,1:-2].values.ravel(), columns = ['PPT'])\n",
        "  ppt_long['site'] = [ele for ele in ppt['site'] for j in range(len(ppt.axes[1])-3)]\n",
        "  ppt_long['year'] = ppt['year'][1]\n",
        "  ppt_long['doy'] = list((range(1,(len(ppt.axes[1])-2))))*len(ppt.index)\n",
        "  if i == 0:\n",
        "    ppt_big = ppt_long\n",
        "  else:\n",
        "    ppt_big = pd.concat([ppt_big,ppt_long])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hVDWacVfIvhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full = pd.merge(ppt_big, tmax_big,  on=['site','year','doy'])\n",
        "full = pd.merge(full, tmin_big,  on=['site','year','doy'])\n",
        "full.to_csv(\"/content/drive/MyDrive/Thesis/Chapter2_simulations/livneh/all_plots_climate.csv\")"
      ],
      "metadata": {
        "id": "3y8esc9-L7ED"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}